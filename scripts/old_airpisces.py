# -*- coding: utf-8 -*-
"""AirPisces.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AH80Oh8f7BgdFo9sZbg78UHz2GaAXWiQ
"""

!pip install tensorflow==2.3.0
!pip install gym
!pip install keras
!pip install keras-rl2
!pip install pygame

import gym
from gym import Env
from gym.spaces import Discrete, Box, MultiDiscrete, Dict
import random

import cv2
from google.colab.patches import cv2_imshow
from google.colab import output
import time 
import os, sys
os.environ["SDL_VIDEODRIVER"] = "dummy"
import pygame
from random import randint
import numpy as np

class Drone():

  def __init__(self, start_pos) -> None:
    self.launched = True
    self.battery = 20
    self.vect = 0
    self.altitude = 1
    self.rotations = [(1,0),(1,1),(0,1),(-1,1),(-1,0),(-1,-1),(0,-1),(1,-1)]
    self.pos = start_pos
    self.current_rot = self.rotations[0]

  def rotate(self, dir):
    self.vect = (self.vect + dir) % 8
  
  def forward(self):
    self.pos = (self.pos[0] + self.rotations[self.vect][0],self.pos[1] + self.rotations[self.vect][1])
    #self.pos = self.pos + self.rotations[self.vect]
    self.battery -= 1

  def right(self):
    self.pos = (self.pos[0] + self.rotations[(self.vect + 2) % 8][0],self.pos[1] + self.rotations[(self.vect + 2) % 8][1])
    self.battery -= 1
    #self.pos = self.pos + self.rotations[(self.vect + 2) % 8]
    
  def backward(self):
    self.pos = (self.pos[0] + self.rotations[(self.vect + 4) % 8][0],self.pos[1] + self.rotations[(self.vect + 4) % 8][1])    
    self.battery -= 1
    #self.pos = self.pos + self.rotations[(self.vect + 4) % 8]
    
  def left(self):
    self.pos = (self.pos[0] + self.rotations[(self.vect + 6) % 8][0],self.pos[1] + self.rotations[(self.vect + 6) % 8][1])
    self.battery -= 1
    #self.pos = self.pos + self.rotations[(self.vect + 6) % 8]
    
  def up(self):
    self.altitude += 1
    self.battery -= 1
    
  def down(self):
    self.altitude -= 1
    self.battery -= 1
    

  def draw_drone(self, screen, block_size):
    self.current_rot = self.rotations[self.vect]
    radius = 10
    blue = (0, 0, 255)
    arrow_col = (199,21,133)

    x =  self.pos[0] * block_size + block_size/2
    y =  self.pos[1] * block_size + block_size/2
    circle = pygame.draw.circle(screen, blue, (x, y), radius)
    
    # Est
    if self.current_rot == self.rotations[0]:    
      start_arrow = (x + 5 + radius, y)
      arrow_b = (start_arrow[0] - 5, start_arrow[1] + 5)
      arrow_c = (start_arrow[0] - 5, start_arrow[1] - 5)   
    
    # SE
    elif self.current_rot == self.rotations[1]:    
      start_arrow = (x + radius, y + radius)
      arrow_b = (start_arrow[0] - 5, start_arrow[1])
      arrow_c = (start_arrow[0], start_arrow[1] - 5)
    
    # South
    elif self.current_rot == self.rotations[2]:    
      start_arrow = (x, y + 5 + radius)
      arrow_b = (start_arrow[0] - 5, start_arrow[1] - 5)
      arrow_c = (start_arrow[0] + 5, start_arrow[1] - 5)

    # SW
    elif self.current_rot == self.rotations[3]:
      start_arrow = (x - radius, y + radius)
      arrow_b = (start_arrow[0], start_arrow[1] - 5)
      arrow_c = (start_arrow[0] + 5, start_arrow[1])    
      
    # West
    elif self.current_rot == self.rotations[4]:    
      start_arrow = (x - (5 + radius), y)
      arrow_b = (start_arrow[0] + 5, start_arrow[1] + 5)
      arrow_c = (start_arrow[0] + 5, start_arrow[1] - 5)       
    
    # NW
    elif self.current_rot == self.rotations[5]:    
      start_arrow = (x - radius, y - radius)
      arrow_b = (start_arrow[0] + 5, start_arrow[1])
      arrow_c = (start_arrow[0], start_arrow[1] + 5)    
      
    # North
    elif self.current_rot == self.rotations[6]:    
      start_arrow = (x, y - (5 + radius))
      arrow_b = (start_arrow[0] + 5, start_arrow[1] + 5)
      arrow_c = (start_arrow[0] - 5, start_arrow[1] + 5)    
    
    # NE
    elif self.current_rot == self.rotations[7]:
      start_arrow = (x  + radius, y - radius)
      arrow_b = (start_arrow[0] - 5, start_arrow[1])
      arrow_c = (start_arrow[0], start_arrow[1] + 5)    
      
    else:    
      raise Exception("unhandle parameter")
    
    arrow = pygame.draw.polygon(screen, arrow_col, (start_arrow, arrow_b, arrow_c))
    



  """
  Different possible actions :
    0 - SpawnDrone
    1 - Forward
    2 - Right
    3 - Backwards
    4 - Left
    5 - Rotate Right
    6 - Rotate Left
    7 - Up
    8 - Down
    9 - Do task
    10 - Land
  """

from enum import Enum

class Actions(Enum) :
    LAUNCH        = 0
    FORWARD       = 1
    RIGHT         = 2
    BACKWARDS     = 3
    LEFT          = 4
    ROTATE_RIGHT  = 5
    ROTATE_LEFT   = 6
    UP            = 7
    DOWN          = 8
    DO_TASK       = 9 
    LAND          = 10

from gym.spaces.utils import flatten_space
def out_of_bounds(pos, max_h, max_w):
  if (pos[0] < 0 or pos[0] > max_w):
    return False
  if (pos[1] < 0 or pos[1] > max_h):
    return False
  return True

WINDOW_HEIGHT = 768
WINDOW_WIDTH = 1024
block_size = 30
pygame.init()
screen = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))
font_simu = pygame.font.SysFont('liberationmono', block_size, True)

class ManagerEnv(Env):
  def __init__(self, nb_drones, map_real_dims, map_simu_dims, start_pos, targets_pos, obstacles_pos) -> None:
    self.action_space = Discrete(len(Actions) * nb_drones,)

    self.max_op = 100
    self.state = 0
    self.nb_drones = nb_drones
    self.drones = [Drone(start_pos) for i in range(nb_drones)]
    self.map_real_dims = map_real_dims
    self.map_simu_dims = map_simu_dims
    self.start_pos = start_pos
    self.targets_pos = targets_pos
    self.obstacles_pos = obstacles_pos
    self.launched_drones = []
    self.visited_targets = []
    self.max_w = map_simu_dims[0]
    self.max_h = map_simu_dims[1]

    low = np.zeros((2,), dtype=int)
    high = np.array([self.nb_drones, len(self.targets_pos)])



    self.observation_space = Dict(
        {
            "drones": Box(0, len(self.drones), shape=(2,), dtype=int),
            "target": Box(0, len(self.targets_pos), shape=(2,), dtype=int),
            "obstacle": Box(0, len(self.obstacles_pos), shape=(2,), dtype=int),
        }
    )

    """
    self.observation_space = Dict({
        "drones_pos" : Box(0 , self.max_w * self.max_h, shape=(nb_drones,)),
        "obstacles_pos" :  Box(0 , self.max_w * self.max_h, shape=(len(self.obstacles_pos),)),
        "targets_pos" :  Box(0 , self.max_w * self.max_h, shape=(len(self.targets_pos),))
    }) #Box(low, high, dtype=np.int)
    """

    print(self.observation_space)

    # print( pygame.display.list_modes() )
    self.WINDOW_HEIGHT = 768
    self.WINDOW_WIDTH = 1024
    self.MAP_HEIGHT = 750
    self.MAP_WIDTH = 1020
    
    self.done = False
    self.white = (255, 255, 255)
    self.block_size = 30 # in pixelss
    self.wait_time = 0.5 # in seconds
          
  
  def _get_obs(self) : 
    return np.array( [
        self.targets_pos,
        self.obstacles_pos,
        [drone.pos for drone in self.drones]  ]
    )
  def step(self, action):
    self.max_op -= 1
    reward = -1
    done = False

    if (not self.action_space.contains(action)):
      return

    drone_id = action // len(Actions)
    action_id = Actions(action % len(Actions))

    print("drone :", drone_id, "fait", action_id)

    if action_id == Actions.LAUNCH:
      if(not self.drones[drone_id].launched):
        self.drones[drone_id].launched = True
        reward = -10
        #PrintInDroneFile
        self.launched_drones.append(self.drones[drone_id])

    tmp_pos = self.drones[drone_id].pos

    if action_id == Actions.FORWARD:
      if(self.drones[drone_id].launched):
        self.drones[drone_id].forward()
        #PrintInDroneFile
        reward = 1

    if action_id == Actions.RIGHT:
      if(self.drones[drone_id].launched):
        self.drones[drone_id].right()
        #PrintInDroneFile
        reward = 1

    if action_id == Actions.BACKWARDS:
      if(self.drones[drone_id].launched):
        self.drones[drone_id].backward() 
        #PrintInDroneFile
        reward = 1
        
    if action_id == Actions.LEFT:
      if(self.drones[drone_id].launched):
        self.drones[drone_id].left()
        #PrintInDroneFile
        reward = 1
        
    if action_id == Actions.ROTATE_RIGHT:
      if(self.drones[drone_id].launched):
        self.drones[drone_id].rotate(1)
        #PrintInDroneFile
        reward = 1

    if action_id == Actions.ROTATE_LEFT:
      if(self.drones[drone_id].launched):
        self.drones[drone_id].rotate(-1)
        #PrintInDroneFile
        reward = 1

    if action_id == Actions.UP:
      if(self.drones[drone_id].launched):
        #PrintInDroneFile
        self.drones[drone_id].up()
        reward = 1

    if action_id == Actions.DOWN:
      if(self.drones[drone_id].launched):
        #PrintInDroneFile
        self.drones[drone_id].down()
        reward = 1

    if action_id == Actions.DO_TASK:
      if(self.drones[drone_id].launched):
        if (self.drones[drone_id].pos in self.targets_pos and self.drones[drone_id].pos not in self.visited_targets):
          #PrintInDroneFile
          reward = 50
          self.visited_targets.append(self.drones[drone_id].pos)
    
    if action_id == Actions.LAND:
      if (self.drones[drone_id].pos == self.start_pos):
        if (self.drones[drone_id] in self.launched_drones):
          self.launched_drones.remove(self.drones[drone_id])
          #PrintInDroneFile
          reward = 1

    if (out_of_bounds(self.drones[drone_id].pos, self.max_w, self.max_h) or self.drones[drone_id].pos in [(p[0],p[1]) for p in self.obstacles_pos]):
      self.drones[drone_id].pos = tmp_pos
      reward = -1

    elif (self.drones[drone_id].battery <= 0):
      print("Battery done")
      reward = -100
      done = True
        
    if not self.targets_pos and not self.launched_drones :
      "Targets done"
      done = True
      reward = 100

    if (self.max_op <= 0):
      "Maxop done"
      done = True
    print(self.drones[drone_id].pos)
    return (self._get_obs(), reward, done, False, {})

  def _lie_to_env(observation_space):
    pass

      
  

  def __draw_grid(self):
    black = (0, 0, 0)
    for x in range(0, self.MAP_WIDTH, self.block_size):
      for y in range(0, self.MAP_HEIGHT, self.block_size):
        rect = pygame.Rect(x, y, self.block_size, self.block_size)
        pygame.draw.rect(screen, black, rect, 1)


  def __draw_obstacle(self, obstacle_pos):
    black = (0, 0, 0)
    alt_color = (255, 195,0)
    for i in range(0, self.block_size):
      for j in range(0, self.block_size):
        if((i % 2 == 0 and j % 2 == 0) or (i % 2 != 0 and j % 2 != 0)):
          rect = pygame.Rect(obstacle_pos[0] * self.block_size + j, obstacle_pos[1] * self.block_size + i, 1, 1)
          pygame.draw.rect(screen, black, rect, 1)
    if(int(obstacle_pos[2]) > 0 and font_simu != None):
      text_obstacle = font_simu.render(str(obstacle_pos[2]), True, alt_color)
      screen.blit(text_obstacle, (obstacle_pos[0] * self.block_size, obstacle_pos[1] * self.block_size))

  def __draw_target(self, target_pos):
    target_col = (0, 255, 0)
    if(not target_pos[2]):
      pygame.draw.circle(screen, target_col, (target_pos[0] * self.block_size + (self.block_size - 1)/2, target_pos[1] * self.block_size + (self.block_size - 1)/2), self.block_size/2, 5)
  

  def __draw_house(self):
    col_wall = (255,228,225)
    col_door = (165,42,42)
    col_roof = (255,0,0)
    
    wall = pygame.Rect(self.start_pos[0] * self.block_size + (1/5) * self.block_size, self.start_pos[1] * self.block_size  + (2/3) * self.block_size, 20, 10)
    door = pygame.Rect(self.start_pos[0] * self.block_size + (1/2) * self.block_size, self.start_pos[1] * self.block_size  + (5/6) * self.block_size, 2, 5)

    start_roof = (self.start_pos[0] * self.block_size + (1/2) * self.block_size, self.start_pos[1] * self.block_size)
    roof_b = (self.start_pos[0] * self.block_size + self.block_size, self.start_pos[1] * self.block_size + (2/3) * self.block_size)
    roof_c = (self.start_pos[0] * self.block_size, self.start_pos[1] * self.block_size + (2/3) * self.block_size)
    
    pygame.draw.polygon(screen, col_roof, (start_roof,roof_b,roof_c))
    pygame.draw.rect(screen, col_wall, wall)
    pygame.draw.rect(screen, col_door, door)
  
  
  def render(self):
    output.clear()
    screen.fill(self.white)
    self.__draw_grid()
    self.__draw_house()

    for i in range(len(self.obstacles_pos)):
      self.__draw_obstacle(self.obstacles_pos[i])
    for i in range(len(self.targets_pos)):
      self.__draw_target(self.targets_pos[i])
    for i in range(len(self.drones)):
      self.drones[i].draw_drone(screen, self.block_size)

    view = pygame.surfarray.array3d(screen)
    view = view.transpose([1, 0, 2])
    img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)
    cv2_imshow(img_bgr)
    time.sleep(self.wait_time)
    

  def reset(self):
    self.state = 0
    self.launched_drones = []
    self.nb_drones = self.nb_drones
    self.drones = [Drone(self.start_pos) for i in range(self.nb_drones)] 
    return (self._get_obs(), {})

def parser(file_ap):
  f = open(file_ap, "r")
  elems = f.readlines()
  for i in range(len(elems)):
    if elems[i][-1] == "\n":
      elems[i] = elems[i][:-1]
  nb_drones = int(elems[0][0])
  map_meter = elems[1].split()
  map_width_meter = float(map_meter[0])
  map_height_meter = float(map_meter[1])
  nb_items = 0

  targets_pos = []
  obstacles_pos = []
  l = None
  for i in range(2, len(elems)):
    l = elems[i].split() 
    if(len(l) >= 3):
      nb_items += 1
      if(l[0] == "H"):
        start_pos = (int(l[1]), int(l[2]))
      elif(l[0] == "T"):
        targets_pos.append((int(l[1]), int(l[2]), False))
      else:
        raise Exception("unhandle parameter: " + l[0])
    elif(len(l) == 1):
      for j in range(len(l[0])):
        if(l[0][j] == "x"):
          obstacles_pos.append((j,i - 2 - nb_items , 0))
        elif(l[0][j] in "0123456789ABCDEF"):
          if(l[0][j] != "0"):
            obstacles_pos.append((j,i - 2 - nb_items,  l[0][j]))
        else:
          raise Exception("unhandle parameter: " + l[0][j])        
  map_simu_dims = (len(l[0]), len(elems) - nb_items - 2)
  map_real_dims = (map_width_meter, map_height_meter)

  return ManagerEnv(nb_drones, map_real_dims, map_simu_dims, start_pos, targets_pos, obstacles_pos)



import gym 
import random
import numpy as np 
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Flatten, Embedding
from tensorflow.keras.optimizers import Adam

from rl.agents import DQNAgent
from rl.policy import BoltzmannQPolicy
from rl.memory import SequentialMemory
from rl.processors import MultiInputProcessor
from tensorflow.keras.layers import concatenate

from numpy.core.numeric import shape
from tensorflow.keras import Input
env = mana_env

states = flatten_space(env.observation_space).shape
actions = env.action_space.n

print(states)
print(actions)

def build_veryenv(states, actions):
    target = Sequential()
    target.add(Flatten(input_shape=(len(env.targets_pos),), name='targets'))
    target_input = Input(shape=(len(env.targets_pos),), name='targets')
    target_encoded = target(target_input)


    obstacles = Sequential()
    obstacles.add(Flatten(input_shape=(len(env.obstacles_pos),), name='obstacles'))
    obstacles_input = Input(shape=(len(env.obstacles_pos),), name='obstacles')
    obstacles_encoded = obstacles(obstacles_input)


    drones = Sequential()
    drones.add(Flatten(input_shape=(len(env.drones),), name='drones'))
    drones_input = Input(shape=(len(env.drones),), name='drones')
    drones_encoded = drones(drones_input)

    con = concatenate([target_encoded, obstacles_encoded, drones_encoded])

    hidden = Dense(16, activation='relu')(con)
    for _ in range(2): 
      hidden = Dense(16, activation='relu')(hidden)
    output = Dense(actions, activation='linear')(hidden)
    model_final = Model(inputs=[target_input, obstacles_input, drones_input], outputs=output)
    return model_final

def build_model(states, actions):
    drones_model = Sequential()
    drones_model.add(Flatten(input_shape = (len(env.drones),)))
    drones_model.add(Dense(24, activation='relu'))
    
    obstacles_model = Sequential()
    obstacles_model.add(Flatten(input_shape = (len(env.obstacles_pos),)))
    obstacles_model.add(Dense(8, activation='relu'))

    target_model = Sequential()
    target_model.add(Flatten(input_shape = (len(env.targets_pos),)))
    target_model.add(Dense(8, activation='relu'))

    conca_model = concatenate([drones_model, obstacles_model, target_model])

    hidden = Dense(24, activation='relu')(conca_model)
    for _ in range(2): 
        hidden = Dense(16, activation='relu')(hidden)

    output = Dense(actions, activation='linear')(hidden)
    model_final = Model(inputs=[drones_model, obstacles_model, target_model], outputs=output)
    """
    model = Sequential()
   # model.add(Flatten(input_shape=(1, 3, 2, NB_MURS)))
   # model.add(Flatten(input_shape=(states,)))
    
    model.add(Flatten(input_shape=(1, 2)))
    model.add(Embedding(16, 4))
    model.add(Dense(24, activation='relu'))
    model.add(Dense(24, activation='relu'))
    model.add(Flatten())
    model.add(Dense(actions, activation='linear'))
    """
    return model_final

def build_agent(model, actions):
    policy = BoltzmannQPolicy()
    memory = SequentialMemory(limit=50000, window_length=1)
    dqn = DQNAgent(model=model, memory=memory, policy=policy, 
                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)
    dqn.processor = MultiInputProcessor(3)
    return dqn

model = build_veryenv(states, actions)
model.summary()

dqn = build_agent(model, actions)
dqn.compile(Adam(lr=1e-3), metrics=['mae'])
dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)

##### Test #####
# MAX 34x25 block map render 

from google.colab import drive
drive.mount('/content/drive')

# files_ap = "/content/drive/MyDrive/Projet AirPisces/code and co/files_ap/"
files_ap = "/content/drive/MyDrive/files_ap/"


mana_env = parser(files_ap + "test.ap")
#mana_env.render()
print("simu dims", mana_env.map_simu_dims)
print("real dims", mana_env.map_real_dims)

done = False
state = mana_env.reset()
while not done:
    action = mana_env.action_space.sample()
    print(action)
    state, reward, done,_, _ = mana_env.step(action)
    print(state)
    mana_env.render()



